{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SQL de alto desempenho\n",
    "\n",
    "<p><img src=https://irp-cdn.multiscreensite.com/b4e20866/NoSQL.jpg width=500></p>\n",
    "\n",
    "## Introdução\n",
    "No módulo anterior, desenvolvemos as habilidades necessárias para analisar efetivamente os dados em um banco de dados SQL e, neste módulo, voltaremos nossa atenção para a eficiência dessa análise, investigando como podemos aumentar o desempenho de nossas consultas SQL.\n",
    "\n",
    "Eficiência e desempenho são componentes-chave da análise de dados, pois sem considerar esses fatores, restrições físicas, como tempo e poder de processamento, podem afetar significativamente o resultado de uma análise. Para elaborar essas limitações, podemos considerar dois cenários separados.\n",
    "\n",
    "Digamos que estamos realizando uma **análise post-hoc** (análise após o fato ou evento). Neste primeiro cenário, concluímos um estudo e coletamos um grande conjunto de dados de observações individuais de vários fatores ou características diferentes. Um exemplo é o descrito em nosso banco de dados de vendas de concessionárias – analisando os dados de vendas de cada cliente. Com o processo de coleta de dados, queremos analisar os dados em busca de padrões e **insights** conforme especificado por nossa declaração do problema. Se nosso conjunto de dados for suficientemente grande, poderemos encontrar problemas rapidamente se não otimizarmos as consultas primeiro; o problema mais comum seria simplesmente o tempo gasto para executar as consultas. Embora isso não pareça um problema significativo, tempos de processamento desnecessariamente longos podem causar:\n",
    "* Uma redução na profundidade da análise concluída. Como cada consulta leva muito tempo, a praticidade dos cronogramas do projeto pode limitar o número de consultas e, portanto, a profundidade e a complexidade da análise podem ser limitadas.\n",
    "* A limitação da seleção de dados para análise. Ao reduzir artificialmente o conjunto de dados usando subamostragem, podemos concluir a análise em um tempo razoável, mas teríamos que sacrificar o número de observações usadas. Isso pode, por sua vez, levar à inclusão acidental de vieses na análise.\n",
    "* A necessidade de usar muito mais recursos em paralelo para concluir a análise em um tempo razoável, aumentando assim o custo do projeto.\n",
    "\n",
    "Da mesma forma, outro problema potencial com consultas abaixo do ideal é um aumento na memória necessária do sistema e no poder de computação. Isso pode resultar em um dos dois cenários a seguir:\n",
    "* Prevenção da análise devido a recursos insuficientes\n",
    "* Um aumento significativo no custo do projeto para recrutar os recursos necessários\n",
    "\n",
    "Análises/consultas fazem parte de um serviço ou produto. Vamos pensar em um segundo cenário, em que a análise está sendo concluída como um componente de um serviço ou produto maior e, portanto, as consultas ao banco de dados podem precisar ser concluídas em tempo real, ou pelo menos em tempo quase real. Nesses casos, a otimização e a eficiência são fundamentais para o sucesso do produto.\n",
    "\n",
    "Um exemplo é um sistema de navegação GPS que incorpora o estado do tráfego conforme relatado por outros usuários. Para que tal sistema seja eficaz e forneça informações de navegação atualizadas, o banco de dados deve ser analisado a uma taxa que acompanhe a velocidade do carro e o andamento da viagem. Qualquer atraso na análise que impeça a atualização da navegação em resposta ao tráfego teria um impacto significativo na viabilidade comercial do aplicativo.\n",
    "\n",
    "Depois de examinar esses dois exemplos, podemos ver que, embora a eficiência seja importante em uma análise *post-hoc* eficaz e completa, ela é absolutamente crítica ao incorporar a análise de dados como um componente de um produto ou serviço separado. Embora certamente não seja o trabalho de um cientista de dados ou analista de dados garantir que a produção e o banco de dados estejam funcionando com eficiência ideal, é fundamental que as consultas da análise subjacente sejam tão eficazes quanto possível. Se não tivermos um banco de dados eficiente e atual em primeiro lugar, refinamentos adicionais não ajudarão a melhorar o desempenho da análise. Na próxima seção, discutiremos métodos para aumentar o desempenho de varreduras de informações em um banco de dados.\n",
    "\n",
    "### Métodos de verificação de banco de dados\n",
    "Os bancos de dados compatíveis com SQL fornecem vários métodos diferentes para varredura, pesquisa e seleção de dados. O método de verificação correto a ser usado depende muito do caso de uso e do estado do banco de dados no momento da verificação. Quantos registros estão no banco de dados? Em quais campos estamos interessados? Quantos registros esperamos que sejam devolvidos? Com que frequência precisamos executar a consulta? Estas são apenas algumas das perguntas que podemos fazer ao selecionar o método de digitalização mais adequado. Ao longo desta seção, descreveremos alguns dos métodos de pesquisa disponíveis, como eles são usados no SQL para executar varreduras e vários cenários em que eles devem/não devem ser usados."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}